apiVersion: v1
kind: Pod
metadata:
  name: online-inference
  labels:
    app: online-inference
spec:
  containers:
  - name: online-inference
    image: nekronix588/made-inference-mlops:latest
    resources:
      requests:
        memory: 64Mi
        cpu: 100m
      limits:
        memory: 128Mi
        cpu: 200m
    ports:
    - containerPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: online-inference-service
spec:
  selector:
    app: online-inference
  ports:
    # - protocol: TCP
    - port: 8000
      targetPort: 8000
  type: ClusterIP
